{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jJVDoERQz7iX"
   },
   "source": [
    "## Let's break down the code and provide the requested information:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V4ArzTUF0NnR"
   },
   "source": [
    "# DEPENDENCIES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PUg4CIpF0S_B"
   },
   "source": [
    "**Various dependencies used in my code are these.**\n",
    "\n",
    "1. Google Colab: This is a cloud-based platform that provides access to Python and various machine learning libraries.\n",
    "\n",
    "  1.1 The code is running in T4-GPU.\n",
    "\n",
    "2. numpy (np): Used for numerical operations and data manipulation.\n",
    "\n",
    "3. matplotlib.pyplot (plt): Used for data visualization, particularly plotting graphs and charts.\n",
    "\n",
    "4. pandas (pd): Used for data manipulation and working with data in tabular form.\n",
    "\n",
    "5. PIL (Pillow): Python Imaging Library, used for opening and manipulating images.\n",
    "\n",
    "6. torch: The PyTorch library, used for deep learning and building neural networks.\n",
    "\n",
    "7. os: The Python os module, used for working with the file system, including file and directory operations.\n",
    "\n",
    "8. torch.nn (nn): Part of PyTorch, used for defining and training neural networks.\n",
    "\n",
    "9. torch.optim (optim): Part of PyTorch, used for optimization algorithms like Adam.\n",
    "\n",
    "10. torch.utils.data: Part of PyTorch, used for creating data loaders for efficient data handling.\n",
    "\n",
    "11. torchvision.models: Part of PyTorch, provides pre-trained deep learning models.\n",
    "\n",
    "12. torchvision.transforms (transforms): Part of PyTorch, used for image data transformations.\n",
    "\n",
    "13. sklearn.metrics: From scikit-learn, used for calculating metrics like ROC AUC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aFtXfd9b0uRd"
   },
   "source": [
    "# **OUTPUT DATA WHEN THEY ARE STORED:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZtUFKWdc01wS"
   },
   "source": [
    "# The following are data outputs, processed and stored."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RDWXgVBz1AYD"
   },
   "source": [
    "train_data: This is a Pandas DataFrame containing training data. It's read from a CSV file located at '/content/drive/MyDrive/camerai/Train.csv'.\n",
    "\n",
    "test_data: Similar to train_data, this is a Pandas DataFrame containing test data, read from a CSV file located at '/content/drive/MyDrive/camerai/Test.csv'.\n",
    "\n",
    "train_images: A list of preprocessed training images loaded from the 'CAMAIRAI BOX READY' directory. These images are resized to 224x224 pixels, converted to tensors, and normalized.\n",
    "\n",
    "test_images: Similar to train_images, a list of preprocessed test images.\n",
    "\n",
    "train_labels: A NumPy array containing target labels (the \"target\" column from train_data).\n",
    "\n",
    "X_train, X_val, y_train, y_val: Data splits for training and validation. Images and labels are split into training and validation sets using train_test_split from scikit-learn.\n",
    "\n",
    "model: A deep learning model based on the ResNet-18 architecture, fine-tuned for your specific task.\n",
    "\n",
    "val_preds: Predicted probabilities for the validation set obtained during model evaluation.\n",
    "\n",
    "val_labels: True labels for the validation set.\n",
    "\n",
    "val_auc: The ROC AUC score calculated for the validation set, indicating the model's performance.\n",
    "\n",
    "test_preds: Predicted probabilities for the test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R5YKB1NZ1I5T"
   },
   "source": [
    "## **FEATURES USED**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jz-VFePr1NdO"
   },
   "source": [
    "In the context of image classification with deep learning, the features are automatically learned by the neural network from the raw image data. Here's what typically happens:\n",
    "\n",
    "The images themselves are the features.\n",
    "\n",
    "These images are preprocessed, resized, normalized, and converted to tensors.\n",
    "\n",
    "The neural network, based on the ResNet-18 architecture, takes these images as input and automatically extracts hierarchical features from them through the various layers of the network.\n",
    "\n",
    "The final fully connected layer of the network (after feature extraction) is responsible for making the binary classification predictions, where it considers the learned features to make a decision.\n",
    "\n",
    "In summary, the deep learning model automatically learns the most relevant features from the input images during the training process, and you don't need to explicitly specify them. The goal is to have the model learn representations that are useful for distinguishing between the classes in your classification task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z-SOCw7K1k57"
   },
   "source": [
    "**Thank you!!!**"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
